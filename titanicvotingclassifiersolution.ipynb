{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-08T01:30:35.313845Z","iopub.execute_input":"2023-01-08T01:30:35.314272Z","iopub.status.idle":"2023-01-08T01:30:35.322416Z","shell.execute_reply.started":"2023-01-08T01:30:35.314238Z","shell.execute_reply":"2023-01-08T01:30:35.321396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\n\n# Read in the training and test sets\ntrain_df = pd.read_csv('/kaggle/input/titanic/train.csv')\ntest_df = pd.read_csv('/kaggle/input/titanic/test.csv')\n\n# Preprocess the data\n\n# Identify most relevant features\n# You can use techniques like feature importance or correlation analysis to help you identify the most important features\nrelevant_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n\n# Handle missing values\nimputer = SimpleImputer(strategy='most_frequent')\ntrain_df[relevant_features] = imputer.fit_transform(train_df[relevant_features])\ntest_df[relevant_features] = imputer.transform(test_df[relevant_features])\n\n# Encode categorical variables as numeric\ntrain_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})\ntest_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})\ntrain_df['Embarked'] = train_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\ntest_df['Embarked'] = test_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n\n# Transform skewed or non-normal features\n# Instead of normalizing all of the numeric features, you could try using techniques like log transformation or Box-Cox transformation to make the distribution of a feature more normal\nscaler = StandardScaler()\ntrain_df[relevant_features] = scaler.fit_transform(train_df[relevant_features])\ntest_df[relevant_features] = scaler.transform(test_df[relevant_features])\n\n# Split the data into features (X) and labels (y)\nX_train = train_df[relevant_features]\ny_train = train_df['Survived']\nX_test = test_df[relevant_features]\n\n# Split the data into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n\n# Train the model\nlog_reg = LogisticRegression()\nbTree = GradientBoostingClassifier(min_samples_split=10)\nsvm = SVC()\nmodel = VotingClassifier(estimators=[('lr', log_reg), ('dt', bTree), ('svm', svm)])\nmodel.fit(X_train, y_train)\n\n\n# Fine-tune the model\nparam_grid = {'n_estimators': [50, 100, 200]}\ngrid_search = GridSearchCV(bTree, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nbest_bTree = grid_search.best_estimator_\nprint(\"Best parameters for Boosted forest: \", grid_search.best_params_)\n\nparam_grid = {'C': [0.1, 1, 10]}\ngrid_search = GridSearchCV(svm, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nbest_svm = grid_search.best_estimator_\nprint(\"Best parameters for SVM: \", grid_search.best_params_)\n\nparam_grid = {'C': [0.1, 1, 10]}\ngrid_search = GridSearchCV(log_reg, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nbest_log_reg = grid_search.best_estimator_\nprint(\"Best parameters for logistic regression: \", grid_search.best_params_)\n\n# Retrain the model with the best individual parameters\nmodel = VotingClassifier(estimators=[('lr', best_log_reg), ('dt', best_bTree), ('svm', best_svm)])\nmodel.fit(X_train, y_train)\n\n# Evaluate the fine-tuned model\ny_pred = model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nprint(\"Accuracy: \", accuracy)\n\n# Fine-tune the voting classifier model using grid search\nparam_grid = {'weights': [[1, 1, 1], [2, 1, 1], [1, 2, 1], [1, 1, 2], [2, 2, 1], [2, 1, 2], [1, 2, 2], [2, 2, 2]]}\nmodel = VotingClassifier(estimators=[('lr', log_reg), ('dt', bTree), ('svm', svm)])\nmodel.fit(X_train, y_train)\ngrid_search = GridSearchCV(model, param_grid, cv=5)\ngrid_search.fit(X_train, y_train)\nbest_model = grid_search.best_estimator_\nprint(\"Best parameters for voting classifier: \", grid_search.best_params_)\n\n# Evaluate the fine-tuned model\ny_pred = best_model.predict(X_val)\naccuracy = accuracy_score(y_val, y_pred)\nprint(\"Accuracy again: \", accuracy)\n\n# Evaluate the logistic regression classifier\nscores = cross_val_score(log_reg, X_train, y_train, cv=5)\nprint(\"Accuracy of logistic regression classifier: \", scores.mean())\n\n# Evaluate the bTree classifier\nscores = cross_val_score(bTree, X_train, y_train, cv=5)\nprint(\"Accuracy of Boosted forest classifier: \", scores.mean())\n\n# Evaluate the SVM classifier\nscores = cross_val_score(svm, X_train, y_train, cv=5)\nprint(\"Accuracy of SVM classifier: \", scores.mean())\n\n\n# Make predictions on the test set\ny_pred = best_model.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': y_pred})\noutput.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-01-08T01:30:35.327973Z","iopub.execute_input":"2023-01-08T01:30:35.328395Z","iopub.status.idle":"2023-01-08T01:30:44.223229Z","shell.execute_reply.started":"2023-01-08T01:30:35.328362Z","shell.execute_reply":"2023-01-08T01:30:44.222014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy:  0.8435754189944135                                 \nBest parameters for random forest:  {'n_estimators': 200}                                        \nBest parameters for SVM:  {'C': 1}                                        \nBest parameters for logistic regression:  {'C': 0.1}                                        ","metadata":{}}]}